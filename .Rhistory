params = params,
data = dados_treino_xgb,
nrounds = 100,
nfold = 5,
metrics = "logloss",
showsd = TRUE,
stratified = TRUE,
print_every_n = 1,
early_stopping_rounds = 3,
maximize = FALSE
)
# Capturando os melhores resultados
best_score <- min(cv$evaluation_log$test_logloss_mean)
best_iteration <- cv$best_iteration
# Adicionando os resultados ao dataframe
cv_results <- rbind(cv_results, cbind(gridsearch_params[i, ], best_score, best_iteration))
}
# Ajustando os nomes das colunas do dataframe de resultados
colnames(cv_results) <- c('eta', 'max_depth', 'min_child_weight', 'subsample', 'colsample_bytree', 'lambda', 'alpha', 'best_score', 'best_iteration')
View(dados_teste_dummy)
colnames(cv_results) <- c('eta', 'max_depth', 'min_child_weight', 'subsample', 'colsample_bytree', 'lambda', 'alpha', 'best_score', 'best_iteration')
# Imprimindo os resultados da otimização rápida
print(cv_results)
View(cv_results)
View(cv_results)
head(cv_results)
cv_results[which.min(cv_results$best_score), ]
View(cv_results[which.min(cv_results$best_score), ])
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.2,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Convertendo as previsões em classes binárias
final_preds_class <- ifelse(final_preds > 0.5, 1, 0)
# Avaliação do modelo com a matriz de confusão e outras métricas
final_conf_matrix <- confusionMatrix(factor(final_preds_class), dados_teste$STATUS)
# Exibindo os resultados da avaliação
print(final_conf_matrix)
modelos_params
write.csv(cv_results, "")
cv_results
write.csv(cv_results, "cv_results.csv")
# Convertendo as previsões em classes binárias
final_preds_class <-
# Avaliação do modelo com a matriz de confusão e outras métricas
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Convertendo as previsões em classes binárias
final_preds_class <-
# Avaliação do modelo com a matriz de confusão e outras métricas
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Exibindo os resultados da avaliação
print(final_conf_matrix)
# Avaliação do modelo com a matriz de confusão e outras métricas
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.2,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Xgboost
dados_treino_xgb <- xgb.DMatrix(data.matrix(dados_treino[,-which(names(dados_treino) == "STATUS")]), label = as.numeric(dados_treino$STATUS)-1)
dados_teste_xgb <- xgb.DMatrix(data.matrix(dados_teste[,-which(names(dados_teste) == "STATUS")]), label = as.numeric(dados_teste$STATUS)-1)
param <- list(
objective = "binary:logistic", # Objetivo para classificação binária
booster = "gbtree",            # Uso de árvores de decisão como boosters
eta = 0.3,                     # Taxa de aprendizado
max_depth = 6                  # Profundidade máxima de cada árvore
)
modelo_xgb <- xgb.train(
params = param,
data = dados_treino_xgb,
nrounds = 100
)
modelo_xgb
rm(param)
previsoes_xgb <- predict(modelo_xgb, newdata = dados_teste_xgb)
confusionMatrix(factor(ifelse(previsoes_xgb > 0.5, 1, 0)), factor(as.numeric(dados_teste$STATUS) - 1))
# Xgboost v2
dados_treino_xgb <- xgb.DMatrix(data.matrix(dados_treino[,-which(names(dados_treino) == "STATUS")]), label = as.numeric(dados_treino$STATUS)-1)
dados_teste_xgb <- xgb.DMatrix(data.matrix(dados_teste[,-which(names(dados_teste) == "STATUS")]), label = as.numeric(dados_teste$STATUS)-1)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.2,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.175,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.15,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.17,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.165,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.172,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
optimized_params <- list(
booster = "gbtree",
eta = 0.174,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
optimized_params <- list(
booster = "gbtree",
eta = 0.171,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.173,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.172,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.172,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.175,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.172,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.172,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.6,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.172,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.8,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.172,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.2,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
# write.csv(cv_results, "cv_results.csv")
# Definindo os hiperparâmetros otimizados com base no resultado da busca em grade
optimized_params <- list(
booster = "gbtree",
eta = 0.172,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.4,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
optimized_params <- list(
booster = "gbtree",
eta = 0.172,
max_depth = 9,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
lambda = 1,
alpha = 0.5,
objective = "binary:logistic"
)
# Treinando o modelo XGBoost com os hiperparâmetros otimizados
final_model <- xgb.train(
params = optimized_params,
data = dados_treino_xgb,
nrounds = 100
)
# Avaliando o modelo no conjunto de teste
final_preds <- predict(final_model, newdata = dados_teste_xgb)
# Exibindo os resultados da avaliação
confusionMatrix(factor(ifelse(final_preds > 0.5, 1, 0)), dados_teste$STATUS)
modelos_params
View(modelos_params)
View(gridsearch_params)
View(cv_results)
