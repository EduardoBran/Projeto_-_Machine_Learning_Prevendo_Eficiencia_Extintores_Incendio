## Avaliando e Visualizando Desempenho dos Modelos
previsoes_rf <- predict(modelo_rf, newdata = dados_teste)
previsoes_svm <- predict(modelo_svm, newdata = dados_teste)
previsoes_glm <- predict(modelo_glm, newdata = dados_teste, type = 'response')
previsoes_xgb <- predict(modelo_xgb, newdata = dados_teste_xgb)
conf_mat_rf <- confusionMatrix(previsoes_rf, dados_teste$STATUS)
conf_mat_svm <- confusionMatrix(previsoes_svm, dados_teste$STATUS)
conf_mat_glm <- confusionMatrix(factor(ifelse(previsoes_glm > 0.5, 1, 0)), dados_teste$STATUS)
conf_mat_xgb <- confusionMatrix(factor(ifelse(previsoes_xgb > 0.5, 1, 0)), factor(as.numeric(dados_teste$STATUS) - 1))
resultados_modelos[['Versao8_rf']] <- list(
Accuracy = round(conf_mat_rf$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_rf$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_rf$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_rf$byClass['Balanced Accuracy'], 4)
)
resultados_modelos[['Versao8_svm']] <- list(
Accuracy = round(conf_mat_svm$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_svm$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_svm$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_svm$byClass['Balanced Accuracy'], 4)
)
resultados_modelos[['Versao8_glm']] <- list(
Accuracy = round(conf_mat_glm$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_glm$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_glm$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_glm$byClass['Balanced Accuracy'], 4)
)
resultados_modelos[['Versao8_xgb']] <- list(
Accuracy = round(conf_mat_xgb$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_xgb$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_xgb$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_xgb$byClass['Balanced Accuracy'], 4)
)
rm(previsoes_rf, previsoes_svm, previsoes_glm, previsoes_xgb)
rm(conf_mat_rf, conf_mat_svm, conf_mat_glm, conf_mat_xgb)
# Precisamos treinar o modelo novamente com um parâmetro adicional para SHAP (predcontrib)
param <- list(
objective = "binary:logistic",
booster = "gbtree",
eta = 0.3,
max_depth = 6,
nthread = 1, # Para compatibilidade
predict_contributions = TRUE # Parâmetro necessário para SHAP
)
# Treinando o modelo XGBoost com o parâmetro adicional
modelo_xgb <- xgb.train(
params = param,
data = dados_treino_xgb,
nrounds = 100
)
# Usando a biblioteca SHAP no Python via reticulate
# Calcula os valores SHAP
explainer <- shap$TreeExplainer(modelo_xgb)
library(shap)
install.packages("shap", dependencies = TRUE)
#### Versão 8
## Carregando dados
dados <- data.frame(read_xlsx("dataset/Acoustic_Extinguisher_Fire_Dataset.xlsx"))
dados <- dados[complete.cases(dados), ]
str(dados)
# - Converte As Variáveis SIZE, FUEL e a variável alvo STATUS para tipo factor
# - Aplica Normalização Nas Variáveis Numéricas
# - Aplica técnica de Balanceamento da Variável Alvo
# - Aplica Seleção de Variáveis
# - Cria 1 Tipo de Modelo utilizando Seleção de Variáveis (RandomForest)
## Preparação dos Dados
# Convertendo as variáveis
dados[c("SIZE", "FUEL", "STATUS")] <- lapply(dados[c("SIZE", "FUEL", "STATUS")], as.factor)
dim(dados)
str(dados)
summary(dados)
# Aplicando Normalização nas Variáveis Numéricas
numeric_columns <- sapply(dados, is.numeric)
dados_nor <- dados %>%
mutate(across(where(is.numeric), ~ scale(., center = min(.), scale = max(.) - min(.))))
rm(numeric_columns)
# Reverter Normalização
# dados_revertidos <- dados_nor %>%
#   mutate(across(where(is.numeric), ~ (. * (max(dados[, cur_column()]) - min(dados[, cur_column()])) + min(dados[, cur_column()]))))
# Balanceamento da Variável Alvo (Aplicando a técnica SMOTE para balancear a variável alvo)
table(dados_nor$STATUS)
dados_balanceados <- ovun.sample(STATUS ~ ., data = dados_nor, method = "over", N = 2*max(table(dados$STATUS)))$data
table(dados_balanceados$STATUS)
## Criando Modelo
# Dividindo os dados em treino e teste
set.seed(100)
indices <- createDataPartition(dados_balanceados$STATUS, p = 0.80, list = FALSE)
dados_treino <- dados_balanceados[indices, ]
dados_teste <- dados_balanceados[-indices, ]
rm(indices)
# RandomForest
modelo_rf <- randomForest(STATUS ~ AIRFLOW + DISTANCE + FREQUENCY + SIZE + FUEL,
data = dados_treino,
ntree = 100, nodesize = 10, importance = TRUE)
# SVM
modelo_svm <- svm(STATUS ~ AIRFLOW + DISTANCE + FREQUENCY + SIZE + FUEL,
data = dados_treino,
type = "C-classification",
kernel = "radial")
# GLM
modelo_glm <- glm(data = dados_treino, STATUS ~ AIRFLOW + DISTANCE + FREQUENCY + SIZE + FUEL, family = binomial(link = 'logit'))
# Xgboost
dados_treino_xgb <- xgb.DMatrix(data.matrix(dados_treino[,-which(names(dados_treino) == "STATUS")]), label = as.numeric(dados_treino$STATUS)-1)
dados_teste_xgb <- xgb.DMatrix(data.matrix(dados_teste[,-which(names(dados_teste) == "STATUS")]), label = as.numeric(dados_teste$STATUS)-1)
param <- list(
objective = "binary:logistic", # Objetivo para classificação binária
booster = "gbtree",            # Uso de árvores de decisão como boosters
eta = 0.3,                     # Taxa de aprendizado
max_depth = 6                  # Profundidade máxima de cada árvore
)
modelo_xgb <- xgb.train(
params = param,
data = dados_treino_xgb,
nrounds = 100
)
rm(param)
## Avaliando e Visualizando Desempenho dos Modelos
previsoes_rf <- predict(modelo_rf, newdata = dados_teste)
previsoes_svm <- predict(modelo_svm, newdata = dados_teste)
previsoes_glm <- predict(modelo_glm, newdata = dados_teste, type = 'response')
previsoes_xgb <- predict(modelo_xgb, newdata = dados_teste_xgb)
conf_mat_rf <- confusionMatrix(previsoes_rf, dados_teste$STATUS)
conf_mat_svm <- confusionMatrix(previsoes_svm, dados_teste$STATUS)
conf_mat_glm <- confusionMatrix(factor(ifelse(previsoes_glm > 0.5, 1, 0)), dados_teste$STATUS)
conf_mat_xgb <- confusionMatrix(factor(ifelse(previsoes_xgb > 0.5, 1, 0)), factor(as.numeric(dados_teste$STATUS) - 1))
resultados_modelos[['Versao8_rf']] <- list(
Accuracy = round(conf_mat_rf$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_rf$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_rf$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_rf$byClass['Balanced Accuracy'], 4)
)
resultados_modelos[['Versao8_svm']] <- list(
Accuracy = round(conf_mat_svm$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_svm$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_svm$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_svm$byClass['Balanced Accuracy'], 4)
)
resultados_modelos[['Versao8_glm']] <- list(
Accuracy = round(conf_mat_glm$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_glm$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_glm$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_glm$byClass['Balanced Accuracy'], 4)
)
resultados_modelos[['Versao8_xgb']] <- list(
Accuracy = round(conf_mat_xgb$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_xgb$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_xgb$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_xgb$byClass['Balanced Accuracy'], 4)
)
library(randomForest)   # carrega algoritimo de ML (randomForest)
library(e1071)          # carrega algoritimo de ML (SVM)
library(gbm)            # carrega algoritimo de ML (GBM)
library(xgboost)        # carrega algoritimo de ML (XgBoost)
library(neuralnet)      # carrega algoritimo de ML (Redes Neurais)
library(class)          # carrega algoritimo de ML (k-NN)
library(rpart)          # carrega algoritimo de ML (Decision Trees)
library(e1071)          # carrega algoritimo de ML (Naive Bayes)
# k-Nearest Neighbors (k-NN)
dados_treino_dummy <- model.matrix(~ . -1 -STATUS, data = dados_treino)
dados_teste_dummy <- model.matrix(~ . -1 -STATUS, data = dados_teste)
knn_pred <- knn(train = dados_treino_dummy, test = dados_teste_dummy, cl = dados_treino$STATUS, k = 5)
conf_mat_knn <- confusionMatrix(knn_pred, dados_teste$STATUS)
conf_mat_knn
modelo_knn <- knn(train = dados_treino_dummy, test = dados_teste_dummy, cl = dados_treino$STATUS, k = 5)
modelo_knn
summary(modelo_knn)
str(modelo_knn)
previsoes_knn <- predict(modelo_knn, newdata = dados_teste$STATUS)
conf_mat_knn <- confusionMatrix(modelo_knn, dados_teste$STATUS)
resultados_modelos[['Versao8_knn']] <- list(
Accuracy = round(conf_mat_knn$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_knn$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_knn$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_knn$byClass['Balanced Accuracy'], 4)
)
modelos_params <- do.call(rbind, lapply(resultados_modelos, function(x) data.frame(t(unlist(x))))) # Convertendo a lista de resultados em um dataframe
modelos_params
# k-Nearest Neighbors (k-NN)
dados_treino_dummy <- model.matrix(~ . -1 -STATUS, data = dados_treino)
dados_teste_dummy <- model.matrix(~ . -1 -STATUS, data = dados_teste)
modelo_knn <- knn(train = dados_treino_dummy, test = dados_teste_dummy, cl = dados_treino$STATUS, k = 5)
resultados_modelos[['Versao8_knn']] <- list(
Accuracy = round(conf_mat_knn$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_knn$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_knn$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_knn$byClass['Balanced Accuracy'], 4)
)
## Adicionando Resultados das Versões em um DataFrame
modelos_params <- do.call(rbind, lapply(resultados_modelos, function(x) data.frame(t(unlist(x))))) # Convertendo a lista de resultados em um dataframe
modelos_params
dados_treino_dummy <- model.matrix(~ . -1 -STATUS, data = dados_treino)
dados_teste_dummy <- model.matrix(~ . -1 -STATUS, data = dados_teste)
naive_model <- naiveBayes(dados_treino_dummy, as.factor(dados_treino$STATUS))
modelo_nai <- naiveBayes(dados_treino_dummy, as.factor(dados_treino$STATUS))
previsoes_nai <- predict(modelo_nai, dados_teste_dummy)
conf_mat_nai <- confusionMatrix(previsoes_nai, dados_teste$STATUS)
resultados_modelos[['Versao8_nai']] <- list(
Accuracy = round(conf_mat_nai$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_nai$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_nai$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_nai$byClass['Balanced Accuracy'], 4)
)
modelos_params <- do.call(rbind, lapply(resultados_modelos, function(x) data.frame(t(unlist(x))))) # Convertendo a lista de resultados em um dataframe
modelos_params
modelo_tre <- rpart(STATUS ~ ., data = dados_treino, method = "class")
previsoes_tre <- predict(modelo_tre, dados_teste, type = "class")
conf_mat_tre <- confusionMatrix(previsoes_tre, dados_teste$STATUS)
resultados_modelos[['Versao8_tre']] <- list(
Accuracy = round(conf_mat_tre$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_tre$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_tre$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_tre$byClass['Balanced Accuracy'], 4)
)
## Adicionando Resultados das Versões em um DataFrame
modelos_params <- do.call(rbind, lapply(resultados_modelos, function(x) data.frame(t(unlist(x))))) # Convertendo a lista de resultados em um dataframe
modelos_params
#### Versão 8
## Carregando dados
dados <- data.frame(read_xlsx("dataset/Acoustic_Extinguisher_Fire_Dataset.xlsx"))
dados <- dados[complete.cases(dados), ]
str(dados)
# - Converte As Variáveis SIZE, FUEL e a variável alvo STATUS para tipo factor
# - Aplica Normalização Nas Variáveis Numéricas
# - Aplica técnica de Balanceamento da Variável Alvo
# - Aplica Seleção de Variáveis
# - Cria 1 Tipo de Modelo utilizando Seleção de Variáveis (RandomForest)
## Preparação dos Dados
# Convertendo as variáveis
dados[c("SIZE", "FUEL", "STATUS")] <- lapply(dados[c("SIZE", "FUEL", "STATUS")], as.factor)
dim(dados)
str(dados)
summary(dados)
# Aplicando Normalização nas Variáveis Numéricas
numeric_columns <- sapply(dados, is.numeric)
dados_nor <- dados %>%
mutate(across(where(is.numeric), ~ scale(., center = min(.), scale = max(.) - min(.))))
rm(numeric_columns)
# Reverter Normalização
# dados_revertidos <- dados_nor %>%
#   mutate(across(where(is.numeric), ~ (. * (max(dados[, cur_column()]) - min(dados[, cur_column()])) + min(dados[, cur_column()]))))
# Balanceamento da Variável Alvo (Aplicando a técnica SMOTE para balancear a variável alvo)
table(dados_nor$STATUS)
dados_balanceados <- ovun.sample(STATUS ~ ., data = dados_nor, method = "over", N = 2*max(table(dados$STATUS)))$data
table(dados_balanceados$STATUS)
## Criando Modelo
# Dividindo os dados em treino e teste
set.seed(100)
indices <- createDataPartition(dados_balanceados$STATUS, p = 0.80, list = FALSE)
dados_treino <- dados_balanceados[indices, ]
dados_teste <- dados_balanceados[-indices, ]
rm(indices)
# RandomForest
modelo_rf <- randomForest(STATUS ~ AIRFLOW + DISTANCE + FREQUENCY + SIZE + FUEL,
data = dados_treino,
ntree = 100, nodesize = 10, importance = TRUE)
# SVM
modelo_svm <- svm(STATUS ~ AIRFLOW + DISTANCE + FREQUENCY + SIZE + FUEL,
data = dados_treino,
type = "C-classification",
kernel = "radial")
# GLM
modelo_glm <- glm(data = dados_treino, STATUS ~ AIRFLOW + DISTANCE + FREQUENCY + SIZE + FUEL, family = binomial(link = 'logit'))
# Xgboost
dados_treino_xgb <- xgb.DMatrix(data.matrix(dados_treino[,-which(names(dados_treino) == "STATUS")]), label = as.numeric(dados_treino$STATUS)-1)
dados_teste_xgb <- xgb.DMatrix(data.matrix(dados_teste[,-which(names(dados_teste) == "STATUS")]), label = as.numeric(dados_teste$STATUS)-1)
param <- list(
objective = "binary:logistic", # Objetivo para classificação binária
booster = "gbtree",            # Uso de árvores de decisão como boosters
eta = 0.3,                     # Taxa de aprendizado
max_depth = 6                  # Profundidade máxima de cada árvore
)
modelo_xgb <- xgb.train(
params = param,
data = dados_treino_xgb,
nrounds = 100
)
rm(param)
# k-Nearest Neighbors (k-NN)
dados_treino_dummy <- model.matrix(~ . -1 -STATUS, data = dados_treino)
dados_teste_dummy <- model.matrix(~ . -1 -STATUS, data = dados_teste)
modelo_knn <- knn(train = dados_treino_dummy, test = dados_teste_dummy, cl = dados_treino$STATUS, k = 5)
# Naive Bayes
dados_treino_dummy <- model.matrix(~ . -1 -STATUS, data = dados_treino)
dados_teste_dummy <- model.matrix(~ . -1 -STATUS, data = dados_teste)
modelo_nai <- naiveBayes(dados_treino_dummy, as.factor(dados_treino$STATUS))
# Decision Trees
set.seed(100)
modelo_tre <- rpart(STATUS ~ ., data = dados_treino, method = "class")
## Avaliando e Visualizando Desempenho dos Modelos
previsoes_rf <- predict(modelo_rf, newdata = dados_teste)
previsoes_svm <- predict(modelo_svm, newdata = dados_teste)
previsoes_glm <- predict(modelo_glm, newdata = dados_teste, type = 'response')
previsoes_xgb <- predict(modelo_xgb, newdata = dados_teste_xgb)
previsoes_nai <- predict(modelo_nai, dados_teste_dummy)
previsoes_tre <- predict(modelo_tre, dados_teste, type = "class")
conf_mat_rf <- confusionMatrix(previsoes_rf, dados_teste$STATUS)
conf_mat_svm <- confusionMatrix(previsoes_svm, dados_teste$STATUS)
conf_mat_glm <- confusionMatrix(factor(ifelse(previsoes_glm > 0.5, 1, 0)), dados_teste$STATUS)
conf_mat_xgb <- confusionMatrix(factor(ifelse(previsoes_xgb > 0.5, 1, 0)), factor(as.numeric(dados_teste$STATUS) - 1))
conf_mat_knn <- confusionMatrix(modelo_knn, dados_teste$STATUS)
conf_mat_nai <- confusionMatrix(previsoes_nai, dados_teste$STATUS)
conf_mat_tre <- confusionMatrix(previsoes_tre, dados_teste$STATUS)
resultados_modelos[['Versao8_rf']] <- list(
Accuracy = round(conf_mat_rf$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_rf$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_rf$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_rf$byClass['Balanced Accuracy'], 4)
)
resultados_modelos[['Versao8_svm']] <- list(
Accuracy = round(conf_mat_svm$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_svm$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_svm$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_svm$byClass['Balanced Accuracy'], 4)
)
resultados_modelos[['Versao8_glm']] <- list(
Accuracy = round(conf_mat_glm$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_glm$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_glm$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_glm$byClass['Balanced Accuracy'], 4)
)
resultados_modelos[['Versao8_xgb']] <- list(
Accuracy = round(conf_mat_xgb$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_xgb$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_xgb$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_xgb$byClass['Balanced Accuracy'], 4)
)
resultados_modelos[['Versao8_knn']] <- list(
Accuracy = round(conf_mat_knn$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_knn$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_knn$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_knn$byClass['Balanced Accuracy'], 4)
)
resultados_modelos[['Versao8_nai']] <- list(
Accuracy = round(conf_mat_nai$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_nai$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_nai$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_nai$byClass['Balanced Accuracy'], 4)
)
resultados_modelos[['Versao8_tre']] <- list(
Accuracy = round(conf_mat_tre$overall['Accuracy'], 4),
Sensitivity = round(conf_mat_tre$byClass['Sensitivity'], 4),
Specificity = round(conf_mat_tre$byClass['Specificity'], 4),
Balanced_Accuracy = round(conf_mat_tre$byClass['Balanced Accuracy'], 4)
)
## Adicionando Resultados das Versões em um DataFrame
modelos_params <- do.call(rbind, lapply(resultados_modelos, function(x) data.frame(t(unlist(x))))) # Convertendo a lista de resultados em um dataframe
modelos_params
# Xgboost
dados_treino_xgb <- xgb.DMatrix(data.matrix(dados_treino[,-which(names(dados_treino) == "STATUS")]), label = as.numeric(dados_treino$STATUS)-1)
dados_teste_xgb <- xgb.DMatrix(data.matrix(dados_teste[,-which(names(dados_teste) == "STATUS")]), label = as.numeric(dados_teste$STATUS)-1)
param <- list(
objective = "binary:logistic", # Objetivo para classificação binária
booster = "gbtree",            # Uso de árvores de decisão como boosters
eta = 0.3,                     # Taxa de aprendizado
max_depth = 6                  # Profundidade máxima de cada árvore
)
modelo_xgb <- xgb.train(
params = param,
data = dados_treino_xgb,
nrounds = 100
)
rm(param)
modelo_xgb
# Xgboost v2
control <- trainControl(method = "cv", number = 10, search = "random")  # # configuração de controle para treinamento com validação cruzada
# Grade de hiperparâmetros para ajuste
grid <- expand.grid(
nrounds = 100,
eta = c(0.01, 0.05, 0.1, 0.3),
max_depth = c(3, 6, 9, 12),
gamma = c(0, 0.1, 0.2, 0.3),
colsample_bytree = c(0.5, 0.7, 1),
min_child_weight = c(1, 5, 10),
subsample = c(0.5, 0.7, 1)
)
# Treinamento do modelo com ajuste de hiperparâmetros
modelo_xgb2 <- train(
data = dados_treino_xgb,
trControl = control,
tuneGrid = grid,
method = "xgbTree"
)
dados_treino_xgb <- xgb.DMatrix(data.matrix(dados_treino[,-which(names(dados_treino) == "STATUS")]), label = as.numeric(dados_treino$STATUS)-1)
dados_teste_xgb <- xgb.DMatrix(data.matrix(dados_teste[,-which(names(dados_teste) == "STATUS")]), label = as.numeric(dados_teste$STATUS)-1)
# Treinamento do modelo com ajuste de hiperparâmetros
modelo_xgb2 <- train(
data = dados_treino_xgb,
trControl = control,
tuneGrid = grid,
method = "xgbTree"
)
# Definindo os parâmetros para a busca em grade
gridsearch_params <- expand.grid(
eta = c(0.01, 0.05, 0.1, 0.3),
max_depth = c(3, 6, 9, 12),
min_child_weight = c(1, 2, 3),
subsample = c(0.5, 0.75, 1),
colsample_bytree = c(0.5, 0.75, 1),
lambda = c(0.5, 1, 1.5),
alpha = c(0, 0.5, 1)
)
# Armazenar as métricas finais para cada combinação
cv_results <- data.frame()
# Loop sobre os parâmetros do gridsearch
for(i in 1:nrow(gridsearch_params)) {
# Atualizar os parâmetros
param <- list(
objective = "binary:logistic",
booster = "gbtree",
eta = gridsearch_params$eta[i],
max_depth = gridsearch_params$max_depth[i],
min_child_weight = gridsearch_params$min_child_weight[i],
subsample = gridsearch_params$subsample[i],
colsample_bytree = gridsearch_params$colsample_bytree[i],
lambda = gridsearch_params$lambda[i],
alpha = gridsearch_params$alpha[i]
)
# Executar a validação cruzada
cv <- xgb.cv(
params = param,
data = dados_treino_xgb,
nrounds = 100,
nfold = 5,
showsd = TRUE,
stratified = TRUE,
print_every_n = 10,
early_stopping_rounds = 10,
maximize = FALSE
)
# Guardar os resultados
best_iteration <- cv$best_iteration
best_score <- min(cv$evaluation_log$test_binary_logloss_mean)
# Adicionar os resultados
cv_results <- rbind(cv_results, c(gridsearch_params[i,], best_score, best_iteration))
}
# Nomear as colunas do dataframe de resultados
colnames(cv_results) <- c('eta', 'max_depth', 'min_child_weight', 'subsample', 'colsample_bytree', 'lambda', 'alpha', 'best_score', 'best_iteration')
# Encontrar os melhores parâmetros
best_params <- cv_results[which.min(cv_results$best_score),]
print(best_params)
# Definindo os parâmetros para a busca em grade
gridsearch_params <- expand.grid(
eta = c(0.01, 0.05, 0.1, 0.3),
max_depth = c(3, 6, 9, 12),
min_child_weight = c(1, 2, 3),
subsample = c(0.5, 0.75, 1),
colsample_bytree = c(0.5, 0.75, 1),
lambda = c(0.5, 1, 1.5),
alpha = c(0, 0.5, 1)
)
# Inicializar cv_results com colunas nomeadas
cv_results <- data.frame(
eta = numeric(),
max_depth = integer(),
min_child_weight = numeric(),
subsample = numeric(),
colsample_bytree = numeric(),
lambda = numeric(),
alpha = numeric(),
best_score = numeric(),
best_iteration = integer(),
stringsAsFactors = FALSE
)
# Loop sobre os parâmetros do gridsearch
for(i in 1:nrow(gridsearch_params)) {
message("Iteration: ", i)
# Atualizar os parâmetros
param <- list(
objective = "binary:logistic",
booster = "gbtree",
eta = gridsearch_params$eta[i],
max_depth = gridsearch_params$max_depth[i],
min_child_weight = gridsearch_params$min_child_weight[i],
subsample = gridsearch_params$subsample[i],
colsample_bytree = gridsearch_params$colsample_bytree[i],
lambda = gridsearch_params$lambda[i],
alpha = gridsearch_params$alpha[i]
)
# Tenta executar a validação cruzada
tryCatch({
cv <- xgb.cv(
params = param,
data = dados_treino_xgb,
nrounds = 100,
nfold = 5,
showsd = TRUE,
stratified = TRUE,
print_every_n = 10,
early_stopping_rounds = 10,
maximize = FALSE
)
# Guardar os resultados
best_iteration <- cv$best_iteration
best_score <- min(cv$evaluation_log$test_binary_logloss_mean)
# Adicionar os resultados
temp_results <- data.frame(
eta = gridsearch_params$eta[i],
max_depth = gridsearch_params$max_depth[i],
min_child_weight = gridsearch_params$min_child_weight[i],
subsample = gridsearch_params$subsample[i],
colsample_bytree = gridsearch_params$colsample_bytree[i],
lambda = gridsearch_params$lambda[i],
alpha = gridsearch_params$alpha[i],
best_score = best_score,
best_iteration = best_iteration,
stringsAsFactors = FALSE
)
cv_results <- rbind(cv_results, temp_results)
}, error = function(e) {
message("Error in iteration ", i, ": ", e$message)
})
}
